{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=1000, n_features=2, cluster_std=1.0, centers=[(-2, 0), (2, 0)], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(y_test.size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(X, W, b):\n",
    "    Z = np.dot(X, W) + b\n",
    "    return 1. / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, b):\n",
    "    p = prob(X, W, b)\n",
    "    return (p > .5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, y, W, b):\n",
    "    p = prob(X, W, b)\n",
    "    l = -y * np.log(p) - (1 - y) * np.log(1 - p)\n",
    "    return l.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_loss(X, y, W, b):\n",
    "    m = X.shape[0]\n",
    "    p = prob(X, W, b)\n",
    "    dLdw = (1. / m) * np.dot(X.T, (p - y))\n",
    "    dLdb = (1. / m) * np.sum((p - y), axis = 0, keepdims = True)\n",
    "    return dLdw, dLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.random((2, 1))\n",
    "b = np.random.random((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71270407],\n",
       "       [0.25680058]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40654323]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.08532981636962035 0.9755555555555555 0.1019336985827512 0.97\n",
      "20 0.08478097038327222 0.9755555555555555 0.10139511124826735 0.97\n",
      "40 0.08424929670397785 0.9755555555555555 0.10087371850500071 0.97\n",
      "60 0.08373398314849421 0.9755555555555555 0.10036870416186883 0.97\n",
      "80 0.08323426869791989 0.9755555555555555 0.09987930343031365 0.97\n",
      "100 0.08274943949769936 0.9755555555555555 0.09940479891435462 0.97\n",
      "120 0.08227882522899506 0.9755555555555555 0.09894451697176318 0.97\n",
      "140 0.0818217958116876 0.9755555555555555 0.09849782440678913 0.97\n",
      "160 0.08137775840406271 0.9755555555555555 0.09806412545962954 0.97\n",
      "180 0.08094615466839557 0.9755555555555555 0.0976428590619514 0.97\n",
      "200 0.08052645827525073 0.9755555555555555 0.0972334963313614 0.97\n",
      "220 0.08011817262245198 0.9755555555555555 0.09683553828083279 0.97\n",
      "240 0.07972082874741111 0.9755555555555555 0.09644851372181767 0.97\n",
      "260 0.07933398341389486 0.9755555555555555 0.09607197734215067 0.97\n",
      "280 0.07895721735639999 0.9755555555555555 0.09570550794193063 0.97\n",
      "300 0.07859013366714136 0.9755555555555555 0.09534870681239427 0.97\n",
      "320 0.07823235631227117 0.9766666666666667 0.09500119624440183 0.97\n",
      "340 0.07788352876536543 0.9766666666666667 0.09466261815456908 0.97\n",
      "360 0.07754331274746733 0.9766666666666667 0.09433263281832943 0.97\n",
      "380 0.07721138706408308 0.9766666666666667 0.09401091770031245 0.97\n",
      "400 0.0768874465305045 0.9766666666666667 0.0936971663734032 0.97\n",
      "420 0.07657120097770152 0.9766666666666667 0.09339108751871258 0.97\n",
      "440 0.07626237433179796 0.9766666666666667 0.09309240399945937 0.97\n",
      "460 0.07596070376083024 0.9766666666666667 0.09280085200244953 0.97\n",
      "480 0.07566593888309939 0.9766666666666667 0.09251618024144935 0.97\n",
      "500 0.07537784103196951 0.9766666666666667 0.09223814921729089 0.97\n",
      "520 0.07509618257245643 0.9766666666666667 0.09196653053003995 0.97\n",
      "540 0.07482074626538172 0.9766666666666667 0.09170110623898749 0.97\n",
      "560 0.07455132467525981 0.9766666666666667 0.09144166826661831 0.97\n",
      "580 0.07428771961843504 0.9766666666666667 0.09118801784306159 0.97\n",
      "600 0.0740297416482997 0.9766666666666667 0.0909399649878408 0.97\n",
      "620 0.07377720957470696 0.9766666666666667 0.09069732802602465 0.97\n",
      "640 0.07352995001494768 0.9766666666666667 0.09045993313613743 0.97\n",
      "660 0.0732877969738883 0.9766666666666667 0.09022761392741327 0.97\n",
      "680 0.07305059145107617 0.9766666666666667 0.09000021104419086 0.97\n",
      "700 0.07281818107280402 0.9766666666666667 0.08977757179543064 0.97\n",
      "720 0.0725904197472963 0.9766666666666667 0.08955954980750633 0.97\n",
      "740 0.07236716734133224 0.9766666666666667 0.08934600469857804 0.97\n",
      "760 0.07214828937676097 0.9766666666666667 0.08913680177299228 0.97\n",
      "780 0.07193365674548985 0.9766666666666667 0.08893181173428331 0.97\n",
      "800 0.07172314544164136 0.9766666666666667 0.08873091041546215 0.97\n",
      "820 0.07151663630967937 0.9766666666666667 0.08853397852538832 0.97\n",
      "840 0.07131401480740052 0.9766666666666667 0.0883409014101119 0.97\n",
      "860 0.07111517078277246 0.9766666666666667 0.08815156882816189 0.97\n",
      "880 0.07091999826368056 0.9766666666666667 0.08796587473883692 0.97\n",
      "900 0.07072839525971679 0.9766666666666667 0.08778371710262521 0.97\n",
      "920 0.07054026357520995 0.9766666666666667 0.08760499769294877 0.97\n",
      "940 0.07035550863275762 0.9766666666666667 0.08742962191848658 0.97\n",
      "960 0.07017403930657512 0.9766666666666667 0.08725749865538758 0.97\n",
      "980 0.06999576776502721 0.9766666666666667 0.08708854008873462 0.97\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 1000\n",
    "for i in range(num_iterations):\n",
    "    dw, db = grad_loss(X_train, y_train, W, b)\n",
    "    W -= eta * dw\n",
    "    b -= eta * db\n",
    "    if (i % 20) == 0:\n",
    "        y_train_hat = predict(X_train, W, b)\n",
    "        y_test_hat = predict(X_test, W, b)\n",
    "\n",
    "        #print \"%4d: loss(train) = %.3f, acc(train) = %.3f, loss(test) = %.3f, acc(test) = %.3f\" % \\\n",
    "        print (i, loss(X_train, y_train, W, b), (y_train == y_train_hat).mean(), \\\n",
    "        loss(X_test, y_test, W, b), (y_test == y_test_hat).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
